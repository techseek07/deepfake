# Deepfake Detection Using Hybrid Deep Learning Techniques 🎥🧠

A robust, modular pipeline for detecting deepfake content in videos using a hybrid ensemble of deep learning models: **Xception**, **CNN + LSTM**, and **Vision Transformer (ViT)**. This repository includes:

- End-to-end preprocessing, face extraction, labeling, training, and testing  
- A Streamlit app for real-time video analysis and deployment
  

---
<details>
  <summary>📦 Dataset Details</summary>

  The dataset for this project is taken from the [Kaggle Deepfake Detection Challenge](https://www.kaggle.com/competitions/deepfake-detection-challenge/data):

  **Files**
  - `train_sample_videos.zip`  
    A ZIP file containing a sample set of training videos and a `metadata.json` with labels.  
    The full training set is available via the Kaggle competition links.

  - `sample_submission.csv`  
    A sample submission file demonstrating the correct prediction format.

  - `test_videos.zip`  
    A ZIP file containing a small set of videos to be used as a public validation set.

</details>


## 📂 Repository Structure

├── deepdata/ ← Your raw data & outputs
│ ├── train_sample_videos/
│ ├── test_videos/
│ └── metadeta/metadata.json
│
├── preprocess.py ← Image resizing & RGB conversion
├── imagecrop.py ← Frame‐wise face extraction (RetinaFace)
├── labelling.py ← Builds face‐label CSV from metadata
├── train.py ← Trains Xception + CNN+LSTM + ViT ensemble
├── test.py ← Runs inference, frame analysis & plots
├── gpu_test.py ← Checks for GPU availability
├── requirements.txt ← All Python dependencies
│

├── outputs/
│ └── deepfake_ensemble_model.h5
├── app.py ← Main Streamlit application
├── face_extractor.py ← Extracts faces from uploaded videos
├── predictor.py ← Loads model & predicts Fake/Real
└── utils.py ← Shared helper functions

---
#REMEMBER: 1)THE REPOSITORY STRUCUTRE FROM OUTPUTS TO UTILS IS FOR RUNNING THE MODEL ON STREAMLIT, A MODEL IS ALREADY PROVIDED ON THE REPOSITORY'S OUPUT FOLDER.
           2)the streamlit app will use .h5 model file for analyzing and predicitng the integrity of the video, the .h5 file is generated by test.py file.

## 🚀 Getting Started

### 1. Clone & Install
```bash
git clone https://github.com/your-username/deepfake.git
cd deepfake
pip install -r requirements.txt
```

2. Prepare Data
Organize your deepdata/ folder:-
deepdata/
├── train_sample_videos/
├── test_videos/
└── metadeta/metadata.json

3. Run the Core Pipeline
Preprocess & Crop:-
python gpu_test.py
python imagecrop.py
python preprocess.py
Label & Train:-
python labelling.py
python train.py
Test & Visualize:-
python test.py
🌐 Deploy with Streamlit

All Streamlit-related code lives under deepfake_app/.

1. Install Streamlit
If not already included in requirements.txt:-
pip install streamlit plotly
2. Launch the App:-
cd deepfake_app
streamlit run app.py
3. App Workflow
Upload a video (MP4 / MOV / AVI, ≤5 min)
Preview & metadata (resolution, duration, frame rate)
Face extraction (RetinaFace)
Prediction (deepfake_ensemble_model.h5)
Loads via predictor.py
Classifies each face‐frame as Fake (1) or Real (0)
Results dashboard
Fake Probability metric
Analyzed Frames count
Final Verdict:
🔴 FAKE: > 65%
🟡 UNCERTAIN: 35–65%
🟢 REAL: < 35%
Confidence Timeline (Plotly line chart)
Frame Samples grid with per-frame verdicts
🧠 Model Architecture & Loss

Xception (ImageNet backbone)
CNN + LSTM (spatial + short-term temporal features)
Vision Transformer (ViT) (patch-based global context)
Feature Fusion via attention over branch outputs
Weighted Focal Loss to combat Real/Fake imbalance









